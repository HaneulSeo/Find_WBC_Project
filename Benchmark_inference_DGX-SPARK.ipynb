{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fU-wvfL7AZfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T02:43:43.953458Z",
     "iopub.status.busy": "2025-12-06T02:43:43.953305Z",
     "iopub.status.idle": "2025-12-06T02:43:44.360577Z",
     "shell.execute_reply": "2025-12-06T02:43:44.356889Z"
    },
    "id": "fU-wvfL7AZfc",
    "papermill": {
     "duration": 0.412273,
     "end_time": "2025-12-06T02:43:44.363174",
     "exception": false,
     "start_time": "2025-12-06T02:43:43.950901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oAqAQ_ZtAXc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T02:43:44.376027Z",
     "iopub.status.busy": "2025-12-06T02:43:44.375766Z",
     "iopub.status.idle": "2025-12-06T02:43:45.245433Z",
     "shell.execute_reply": "2025-12-06T02:43:45.244619Z"
    },
    "id": "oAqAQ_ZtAXc4",
    "papermill": {
     "duration": 0.882814,
     "end_time": "2025-12-06T02:43:45.247024",
     "exception": false,
     "start_time": "2025-12-06T02:43:44.364210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "KyuglqAIEIbq",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-06T02:43:45.258722Z",
     "iopub.status.busy": "2025-12-06T02:43:45.258594Z",
     "iopub.status.idle": "2025-12-06T02:43:45.260600Z",
     "shell.execute_reply": "2025-12-06T02:43:45.259897Z"
    },
    "id": "KyuglqAIEIbq",
    "papermill": {
     "duration": 0.013114,
     "end_time": "2025-12-06T02:43:45.261098",
     "exception": false,
     "start_time": "2025-12-06T02:43:45.247984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mps or cuda\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a5d4fd-072a-4d5a-a5be-95bbb18fc0f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "execution": {
     "iopub.execute_input": "2025-12-06T02:43:45.262915Z",
     "iopub.status.busy": "2025-12-06T02:43:45.262857Z",
     "iopub.status.idle": "2025-12-06T02:45:12.130236Z",
     "shell.execute_reply": "2025-12-06T02:45:12.129727Z"
    },
    "id": "47a5d4fd-072a-4d5a-a5be-95bbb18fc0f6",
    "outputId": "8127e9f7-0c89-4f6c-c91a-e8d98a1d17df",
    "papermill": {
     "duration": 86.869461,
     "end_time": "2025-12-06T02:45:12.131175",
     "exception": false,
     "start_time": "2025-12-06T02:43:45.261714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 모델 목록: ['models/rt_detr.pt', 'models/yolo10.pt', 'models/yolo10s.pt', 'models/yolon.pt', 'models/yolos.pt']\n",
      "옵션: device='cuda', half=True, 탐지 개수 카운트 포함\n",
      "\n",
      "[models/rt_detr] 벤치마크 진행 중... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jychun/miniconda3/envs/wbc/lib/python3.11/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료! (평균 17.0개 탐지)\n",
      "[models/yolo10] 벤치마크 진행 중... 완료! (평균 10.0개 탐지)\n",
      "[models/yolo10s] 벤치마크 진행 중... 완료! (평균 12.0개 탐지)\n",
      "[models/yolon] 벤치마크 진행 중... 완료! (평균 6.0개 탐지)\n",
      "[models/yolos] 벤치마크 진행 중... 완료! (평균 12.0개 탐지)\n",
      "\n",
      "======================================================================\n",
      "   NVIDIA GB10\n",
      "======================================================================\n",
      "   YOLO 모델 종합 성능 비교 (속도 vs 탐지 개수)\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Avg Detected</th>\n",
       "      <th>Inference (ms)</th>\n",
       "      <th>Total (ms)</th>\n",
       "      <th>FPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>models/yolo10</td>\n",
       "      <td>FP16</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>6.35</td>\n",
       "      <td>157.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>models/yolo10s</td>\n",
       "      <td>FP16</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.71</td>\n",
       "      <td>6.79</td>\n",
       "      <td>147.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>models/yolon</td>\n",
       "      <td>FP16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>9.98</td>\n",
       "      <td>100.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>models/yolos</td>\n",
       "      <td>FP16</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>12.22</td>\n",
       "      <td>81.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>models/rt_detr</td>\n",
       "      <td>FP16</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.03</td>\n",
       "      <td>19.29</td>\n",
       "      <td>51.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Mode  Avg Detected  Inference (ms)  Total (ms)     FPS\n",
       "1   models/yolo10  FP16          10.0            3.67        6.35  157.38\n",
       "2  models/yolo10s  FP16          12.0            3.71        6.79  147.37\n",
       "3    models/yolon  FP16           6.0            2.62        9.98  100.17\n",
       "4    models/yolos  FP16          12.0            2.88       12.22   81.84\n",
       "0  models/rt_detr  FP16          17.0           15.03       19.29   51.83"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 14.1 s, total: 1min 25s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 1. 테스트할 이미지 경로 (본인의 실제 테스트 이미지 경로로 꼭 바꿔주세요!)\n",
    "source_path = 'img_294.png'\n",
    "\n",
    "\n",
    "# 2. 모델 파일 찾기\n",
    "model_files = glob.glob(\"models/*.pt\")\n",
    "model_files.sort()\n",
    "\n",
    "benchmark_data = []\n",
    "\n",
    "print(f\"테스트 모델 목록: {model_files}\")\n",
    "print(f\"옵션: device='{device}', half=True, 탐지 개수 카운트 포함\\n\")\n",
    "\n",
    "for file in model_files:\n",
    "    model_name = os.path.splitext(file)[0]\n",
    "    print(f\"[{model_name}] 벤치마크 진행 중...\", end=\" \")\n",
    "\n",
    "    try:\n",
    "        model = YOLO(file)\n",
    "\n",
    "        # [Warm-up] 예열 10회\n",
    "        for _ in range(10):\n",
    "            model.predict(source=source_path, verbose=False, device=device, half=True)\n",
    "\n",
    "        # [Benchmark] 본 테스트 100회\n",
    "        inference_times = []\n",
    "        preprocess_times = []\n",
    "        postprocess_times = []\n",
    "        detected_counts = []  # 탐지된 개수를 저장할 리스트\n",
    "\n",
    "        for _ in range(100):\n",
    "            results = model.predict(source=source_path, save=False, verbose=False, device='mps', half=True)\n",
    "\n",
    "            # 1. 속도 측정\n",
    "            speed = results[0].speed\n",
    "            preprocess_times.append(speed['preprocess'])\n",
    "            inference_times.append(speed['inference'])\n",
    "            postprocess_times.append(speed['postprocess'])\n",
    "\n",
    "            # 2. 탐지된 WBC 개수 카운트 (Boxes 개수)\n",
    "            # 만약 특정 클래스(예: class 0)만 세야 한다면 results[0].boxes.cls를 필터링해야 합니다.\n",
    "            # 여기서는 모든 탐지 객체를 WBC로 가정하고 전체 개수를 셉니다.\n",
    "            count = len(results[0].boxes)\n",
    "            detected_counts.append(count)\n",
    "\n",
    "        # 평균 계산\n",
    "        avg_infer = sum(inference_times) / len(inference_times)\n",
    "        avg_pre = sum(preprocess_times) / len(preprocess_times)\n",
    "        avg_post = sum(postprocess_times) / len(postprocess_times)\n",
    "        avg_count = sum(detected_counts) / len(detected_counts) # 평균 탐지 개수\n",
    "\n",
    "        total_time_ms = avg_pre + avg_infer + avg_post\n",
    "        fps = 1000 / total_time_ms if total_time_ms > 0 else 0\n",
    "\n",
    "        # 결과 데이터에 추가\n",
    "        benchmark_data.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Mode\": \"FP16\",\n",
    "            \"Avg Detected\": round(avg_count, 1), # 평균 탐지 개수 (소수점 1자리)\n",
    "            \"Inference (ms)\": round(avg_infer, 2),\n",
    "            \"Total (ms)\": round(total_time_ms, 2),\n",
    "            \"FPS\": round(fps, 2)\n",
    "        })\n",
    "\n",
    "        print(f\"완료! (평균 {avg_count:.1f}개 탐지)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"실패 ({e})\")\n",
    "\n",
    "# 3. 결과 테이블 출력\n",
    "if benchmark_data:\n",
    "    df = pd.DataFrame(benchmark_data)\n",
    "    df = df.sort_values(by=\"FPS\", ascending=False)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"   \" + torch.cuda.get_device_name(0))\n",
    "    print(\"=\"*70)\n",
    "    print(\"   YOLO 모델 종합 성능 비교 (속도 vs 탐지 개수)\")\n",
    "    print(\"=\"*70)\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"모델 파일을 찾지 못했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leIWWphnEbr-",
   "metadata": {
    "id": "leIWWphnEbr-",
    "papermill": {
     "duration": 0.001517,
     "end_time": "2025-12-06T02:45:12.134806",
     "exception": false,
     "start_time": "2025-12-06T02:45:12.133289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 89.525438,
   "end_time": "2025-12-06T02:45:12.855746",
   "environment_variables": {},
   "exception": null,
   "input_path": "Benchmark_inference_DGX-SPARK.ipynb",
   "output_path": "Benchmark_inference_DGX-SPARK.out.ipynb",
   "parameters": {},
   "start_time": "2025-12-06T02:43:43.330308",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
